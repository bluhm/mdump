/*
 * Copyright (c) 2022 Martijn van Duren <martijn_openbsd@imperialat.at>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

Otto's recent changes made the diff not apply anymore.
I assume you're still interested, so here's an updated version I made to
accommodate my needs for a new filter-dkimverify I'm working on.

The mdump tool now also shows the maximum memory usage (as far as the
malloc interface is concerned) and allows you to stop processing as soon
as a certain memory threshold has been reached (convenient for tracing
when something isn't leaked, but takes up more memory than expected)

Still a "quick and dirty" tool, but it helped me out.

martijn@

Index: hidden/dlfcn.h
===================================================================
RCS file: /cvs/src/lib/libc/hidden/dlfcn.h,v
retrieving revision 1.4
diff -u -p -r1.4 dlfcn.h
--- hidden/dlfcn.h	9 Oct 2020 16:31:03 -0000	1.4
+++ hidden/dlfcn.h	30 Mar 2022 13:23:56 -0000
@@ -22,9 +22,9 @@
 
 PROTO_NORMAL(dladdr);
 PROTO_DEPRECATED(dlclose);
-PROTO_DEPRECATED(dlerror);
+PROTO_NORMAL(dlerror);
 PROTO_DEPRECATED(dlopen);
-PROTO_DEPRECATED(dlsym);
+PROTO_NORMAL(dlsym);
 PROTO_NORMAL(dlctl);
 
 #endif /* _LIBC_DLFCN_H_ */
Index: stdlib/Makefile.inc
===================================================================
RCS file: /cvs/src/lib/libc/stdlib/Makefile.inc,v
retrieving revision 1.64
diff -u -p -r1.64 Makefile.inc
--- stdlib/Makefile.inc	16 Dec 2017 20:06:55 -0000	1.64
+++ stdlib/Makefile.inc	30 Mar 2022 13:23:56 -0000
@@ -25,6 +25,11 @@ SRCS+=	abs.c div.c labs.c ldiv.c
 SRCS+=	abs.c div.c labs.c ldiv.c
 .endif
 
+.ifdef MALLOC_STATS
+CFLAGS+=-I/usr/include/c++/v1
+CFLAGS+=-DMALLOC_STATS
+.endif
+
 MAN+=	a64l.3 abort.3 abs.3 alloca.3 atexit.3 atof.3 atoi.3 atol.3 atoll.3 \
 	bsearch.3 div.3 ecvt.3 exit.3 getenv.3 getopt.3 getopt_long.3 \
 	getsubopt.3 hcreate.3 imaxabs.3 imaxdiv.3 insque.3 labs.3 ldiv.3 \
Index: stdlib/malloc.c
===================================================================
RCS file: /cvs/src/lib/libc/stdlib/malloc.c,v
retrieving revision 1.273
diff -u -p -r1.273 malloc.c
--- stdlib/malloc.c	26 Feb 2022 16:14:42 -0000	1.273
+++ stdlib/malloc.c	30 Mar 2022 13:23:56 -0000
@@ -39,8 +39,13 @@
 #include <unistd.h>
 
 #ifdef MALLOC_STATS
+#include <sys/atomic.h>
 #include <sys/tree.h>
+#include <sys/param.h>
+#include <sys/ktrace.h>
+#include <dlfcn.h>
 #include <fcntl.h>
+#include <libunwind.h>
 #endif
 
 #include "thread_private.h"
@@ -223,6 +228,7 @@ struct malloc_readonly {
 	size_t	malloc_guard;		/* use guard pages after allocations? */
 #ifdef MALLOC_STATS
 	int	malloc_stats;		/* dump statistics at end */
+	int	malloc_trace;		/* are we tracing? */
 #endif
 	u_int32_t malloc_canary;	/* Matched against ones in pool */
 };
@@ -343,6 +349,102 @@ getrbyte(struct dir_info *d)
 	return x;
 }
 
+#ifdef MALLOC_STATS
+struct traceobject {
+	uintptr_t f;
+	RB_ENTRY(traceobject) entry;
+};
+
+static int
+omalloc_traceobjectcmp(struct traceobject *o1, struct traceobject *o2)
+{
+	return o1->f < o2->f ? -1 : o1->f > o2->f;
+}
+
+RB_HEAD(traceobjecttree, traceobject);
+RB_PROTOTYPE_STATIC(traceobjecttree, traceobject, entry,
+    omalloc_traceobjectcmp);
+RB_GENERATE_STATIC(traceobjecttree, traceobject, entry, omalloc_traceobjectcmp);
+
+static size_t
+omalloc_traceobjectfmt(uintptr_t f, uint8_t *addr)
+{
+	Dl_info info;
+	size_t len;
+	char *error;
+	uint8_t errstr[KTR_USER_MAXLEN];
+
+	if (dladdr((void *)f, &info) == 0) {
+		memcpy(errstr, &f, sizeof(f));
+		len = sizeof(uintptr_t);
+		error = dlerror();
+		len += strlcpy(errstr + sizeof(uintptr_t), error,
+		    sizeof(errstr) - sizeof(uintptr_t));
+		utrace("malloctrobjecterr", errstr, len);
+		return 0;
+	}
+
+	memcpy(addr, &f, sizeof(f));
+	len = sizeof(f);
+	f -= (uintptr_t)info.dli_fbase;
+	memcpy(addr + len, &f, sizeof(f));
+	len += sizeof(f);
+	/*
+	 * XXX realpath would help here for dumping from arbitrary directory.
+	 * This doesn't work because of pledge.
+	 */
+	len += strlcpy(addr + len, info.dli_fname, KTR_USER_MAXLEN - len);
+
+	return len > KTR_USER_MAXLEN ? KTR_USER_MAXLEN : len;
+}
+
+/* ugly hack until I find something better */
+void _spinlock(volatile _atomic_lock_t *);
+void _spinunlock(volatile _atomic_lock_t *);
+
+static void
+omalloc_traceobject(uintptr_t f)
+{
+	static struct traceobjecttree traceobjecttree =
+	    RB_INITIALIZER(&traceobjecttree);
+	static struct traceobject *tobjs = NULL;
+	static size_t ntobjs = 0;
+	struct traceobject *tobj, search;
+	uint8_t tracemem[KTR_USER_MAXLEN];
+	size_t tracelen;
+	static volatile _atomic_lock_t lock = 0;
+
+	search.f = (uintptr_t)f;
+
+	/*
+	 * Don't use per dir_info locking, since that would give a maximum of
+	 * _MALLOC_MUTEXES prints per proces intead of one.
+	 */
+	_spinlock(&lock);
+	if (RB_FIND(traceobjecttree, &traceobjecttree, &search) != NULL)
+		goto out;
+	if ((tracelen = omalloc_traceobjectfmt(f, tracemem)) != 0)
+		utrace("malloctrobject", tracemem, tracelen);
+
+	if (tobjs == NULL || (ntobjs + 1) * sizeof(*tobjs) >= MALLOC_PAGESIZE) {
+		/*
+		 * We need this memory until we exit, no need to keep track of
+		 * it with a realloc-like structure
+		 */
+		if ((tobjs = MMAP(MALLOC_PAGESIZE, 0)) == MAP_FAILED) {
+			tobjs = NULL;
+			goto out;
+		}
+		ntobjs = 0;
+	}
+	tobj = &(tobjs[ntobjs++]);
+	tobj->f = (uintptr_t)f;
+	RB_INSERT(traceobjecttree, &traceobjecttree, tobj);
+out:
+	_spinunlock(&lock);
+}
+#endif
+
 static void
 omalloc_parseopt(char opt)
 {
@@ -407,6 +509,14 @@ omalloc_parseopt(char opt)
 	case 'R':
 		mopts.malloc_realloc = 1;
 		break;
+#ifdef MALLOC_STATS
+	case 't':
+		mopts.malloc_trace = 0;
+		break;
+	case 'T':
+		mopts.malloc_trace++;
+		break;
+#endif
 	case 'u':
 		mopts.malloc_freeunmap = 0;
 		break;
@@ -1207,7 +1317,73 @@ free_bytes(struct dir_info *d, struct re
 	LIST_INSERT_HEAD(mp, info, entries);
 }
 
+#ifdef MALLOC_STATS
+uintptr_t *
+omalloc_backtrace(uintptr_t *bt, size_t nelem)
+{
+	static int (*u_getcontext)(unw_context_t *) = NULL;
+	static int (*u_init_local)(unw_cursor_t *, unw_context_t *) = NULL;
+	static int (*u_step)(unw_cursor_t *) = NULL;
+	static int (*u_get_reg)(unw_cursor_t *, unw_regnum_t, unw_word_t *) = NULL;
+	static volatile unsigned int lock = 0;
+	unw_context_t uc;
+	unw_cursor_t cursor;
+	unw_word_t ip, sp;
+	size_t i;
+
+	if (u_getcontext == NULL) {
+		u_getcontext = dlsym(RTLD_DEFAULT, "unw_getcontext");
+		u_init_local = dlsym(RTLD_DEFAULT, "unw_init_local");
+		u_step = dlsym(RTLD_DEFAULT, "unw_step");
+		u_get_reg = dlsym(RTLD_DEFAULT, "unw_get_reg");
+		if (u_getcontext == NULL || u_init_local == NULL ||
+		    u_step == NULL || u_get_reg == NULL) {
+			u_getcontext = NULL;
+			u_init_local = NULL;
+			u_step = NULL;
+			u_get_reg = NULL;
+		}
+	}
+ 
+	if (u_getcontext != NULL) {
+		/* Make sure we don't recurse back from libunwind */
+		/* XXX This should probably thread local */
+		if (atomic_cas_uint(&lock, 0, 1) != 0)
+			goto builtin;
+		u_getcontext(&uc);
+		u_init_local(&cursor, &uc);
+		u_step(&cursor);
+		for (i = 0; u_step(&cursor) > 0 && nelem > 0; i++) {
+			u_get_reg(&cursor, UNW_REG_IP, &ip);
+			bt[i] = (uintptr_t)ip;
+			omalloc_traceobject(bt[i]);
+			nelem--;
+		}
+		lock = 0;
+		return &(bt[i]);
+	}
+
+ builtin:
+	bt[0] = (uintptr_t)__builtin_return_address(1);
+	omalloc_traceobject(bt[0]);
+	if (nelem > 1) {
+		bt[1] = (uintptr_t)__builtin_return_address(2);
+		omalloc_traceobject(bt[1]);
+		return &(bt[2]);
+		
+	}
+	/* Return address after last element so we can subtract easily */
+	return &(bt[1]);
+}
 
+/* XXX Maybe put this in something like omalloctrace.h? */
+#define MAX_BACKTRACE(used) ((KTR_USER_MAXLEN - (used)) / sizeof(uintptr_t))
+struct malloc_trace {
+	uintptr_t p;
+	size_t sz;
+	uintptr_t bt[MAX_BACKTRACE(sizeof(uintptr_t) + sizeof(size_t))];
+};
+#endif
 
 static void *
 omalloc(struct dir_info *pool, size_t sz, int zero_fill, void *f)
@@ -1389,10 +1565,27 @@ malloc(size_t size)
 	void *r;
 	struct dir_info *d;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct malloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	PROLOGUE(getpool(), "malloc")
 	r = omalloc(d, size, 0, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.sz = size;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("malloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 /*DEF_STRONG(malloc);*/
@@ -1403,10 +1596,27 @@ malloc_conceal(size_t size)
 	void *r;
 	struct dir_info *d;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct malloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	PROLOGUE(mopts.malloc_pool[0], "malloc_conceal")
 	r = omalloc(d, size, 0, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.sz = size;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("malloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 DEF_WEAK(malloc_conceal);
@@ -1562,16 +1772,35 @@ ofree(struct dir_info **argpool, void *p
 	}
 }
 
+struct free_trace {
+	uintptr_t p;
+	uintptr_t bt[MAX_BACKTRACE(sizeof(uintptr_t))];
+};
+
 void
 free(void *ptr)
 {
 	struct dir_info *d;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct free_trace trace;
+	uintptr_t *bt = trace.bt;
+	void *f = CALLER;
+#endif
 
 	/* This is legal. */
 	if (ptr == NULL)
 		return;
 
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace) {
+		trace.p = (uintptr_t)ptr;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("free", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+	}
+#endif
+
 	d = getpool();
 	if (d == NULL)
 		wrterror(d, "free() called before allocation");
@@ -1600,6 +1829,11 @@ freezero(void *ptr, size_t sz)
 {
 	struct dir_info *d;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct free_trace trace;
+	uintptr_t *bt = trace.bt;
+	void *f = CALLER;
+#endif
 
 	/* This is legal. */
 	if (ptr == NULL)
@@ -1615,6 +1849,16 @@ freezero(void *ptr, size_t sz)
 		wrterror(d, "freezero() called before allocation");
 	_MALLOC_LOCK(d->mutex);
 	d->func = "freezero";
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace) {
+		trace.p = (uintptr_t)ptr;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("free", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+	}
+#endif
+
 	if (d->active++) {
 		malloc_recurse(d);
 		return;
@@ -1626,6 +1870,13 @@ freezero(void *ptr, size_t sz)
 }
 DEF_WEAK(freezero);
 
+struct realloc_trace {
+	uintptr_t p;
+	uintptr_t origp;
+	size_t sz;
+	uintptr_t bt[MAX_BACKTRACE((2 * sizeof(uintptr_t)) + sizeof(size_t))];
+};
+
 static void *
 orealloc(struct dir_info **argpool, void *p, size_t newsz, void *f)
 {
@@ -1804,10 +2055,28 @@ realloc(void *ptr, size_t size)
 	struct dir_info *d;
 	void *r;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct realloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	PROLOGUE(getpool(), "realloc")
 	r = orealloc(&d, ptr, size, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.origp = (uintptr_t)ptr;
+		trace.sz = size;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("realloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 /*DEF_STRONG(realloc);*/
@@ -1824,6 +2093,10 @@ calloc(size_t nmemb, size_t size)
 	struct dir_info *d;
 	void *r;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct malloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	PROLOGUE(getpool(), "calloc")
 	if ((nmemb >= MUL_NO_OVERFLOW || size >= MUL_NO_OVERFLOW) &&
@@ -1839,6 +2112,19 @@ calloc(size_t nmemb, size_t size)
 	size *= nmemb;
 	r = omalloc(d, size, 1, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.sz = size;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("malloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 /*DEF_STRONG(calloc);*/
@@ -1849,6 +2135,10 @@ calloc_conceal(size_t nmemb, size_t size
 	struct dir_info *d;
 	void *r;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct malloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	PROLOGUE(mopts.malloc_pool[0], "calloc_conceal")
 	if ((nmemb >= MUL_NO_OVERFLOW || size >= MUL_NO_OVERFLOW) &&
@@ -1864,6 +2154,19 @@ calloc_conceal(size_t nmemb, size_t size
 	size *= nmemb;
 	r = omalloc(d, size, 1, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.sz = size;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("malloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 DEF_WEAK(calloc_conceal);
@@ -1981,6 +2284,10 @@ recallocarray(void *ptr, size_t oldnmemb
 	size_t oldsize = 0, newsize;
 	void *r;
 	int saved_errno = errno;
+#ifdef MALLOC_STATS
+	struct realloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	if (!mopts.internal_funcs)
 		return recallocarray_p(ptr, oldnmemb, newnmemb, size);
@@ -2011,6 +2318,20 @@ recallocarray(void *ptr, size_t oldnmemb
 
 	r = orecallocarray(&d, ptr, oldsize, newsize, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.origp = (uintptr_t)ptr;
+		trace.sz = newsize;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("realloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 DEF_WEAK(recallocarray);
@@ -2157,8 +2478,12 @@ void *
 aligned_alloc(size_t alignment, size_t size)
 {
 	struct dir_info *d;
-	int saved_errno = errno;
 	void *r;
+#ifdef MALLOC_STATS
+	int saved_errno = errno;
+	struct malloc_trace trace;
+	uintptr_t *bt = trace.bt;
+#endif
 
 	/* Make sure that alignment is a positive power of 2. */
 	if (((alignment - 1) & alignment) != 0 || alignment == 0) {
@@ -2174,6 +2499,19 @@ aligned_alloc(size_t alignment, size_t s
 	PROLOGUE(getpool(), "aligned_alloc")
 	r = omemalign(d, alignment, size, 0, CALLER);
 	EPILOGUE()
+
+#ifdef MALLOC_STATS
+	if (mopts.malloc_trace && r != NULL) {
+		saved_errno = errno;
+		trace.p = (uintptr_t)r;
+		trace.sz = size;
+		bt = omalloc_backtrace(bt, mopts.malloc_trace == 1 ?
+		    1 : sizeof(trace.bt) / sizeof(trace.bt[0]));
+		utrace("malloc", &trace, (uintptr_t)bt - (uintptr_t)&(trace));
+		errno = saved_errno;
+	}
+#endif
+
 	return r;
 }
 /*DEF_STRONG(aligned_alloc);*/
@@ -2426,6 +2764,7 @@ malloc_exit(void)
 	int save_errno = errno, fd;
 	unsigned i;
 
+	return;
 	fd = open("malloc.out", O_RDWR|O_APPEND);
 	if (fd != -1) {
 		dprintf(fd, "******** Start dump %s *******\n", __progname);
